{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors, Word2Vec, FastText\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('X.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = pd.read_csv('label.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = label.to_numpy().reshape([1, len(label)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into train data and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,label[0], test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lakshaya Karthikeyan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0. 1.], y=[1. 1. 1. ... 1. 0. 1.] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(y_train),y_train)\n",
    "cw = {0:class_weights[0],1:class_weights[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(class_weight = cw, kernel = 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(class_weight={0: 1.443779108449767,\n",
       "                                         1: 0.764892492069087}),\n",
       "             param_grid={'C': [0.85, 0.9, 0.95]})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'C': [0.85, 0.90, 0.95]}\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.85}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.65      0.60       719\n",
      "         1.0       0.81      0.74      0.77      1452\n",
      "\n",
      "    accuracy                           0.71      2171\n",
      "   macro avg       0.68      0.69      0.69      2171\n",
      "weighted avg       0.72      0.71      0.72      2171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 466,  253],\n",
       "       [ 376, 1076]], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = np.array([[466, 253], [376, 1076]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  : 0.7102717641639797\n",
      "Precision : 0.8096313017306245\n",
      "F1-Score  : 0.7738223660553757\n",
      "Recall    : 0.7410468319559229\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy  :\",accuracy_score(y_test, y_pred))\n",
    "print(\"Precision :\",precision_score(y_test,y_pred))\n",
    "print(\"F1-Score  :\",f1_score(y_test,y_pred))\n",
    "print(\"Recall    :\",recall_score(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
